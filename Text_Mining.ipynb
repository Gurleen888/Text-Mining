{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QXDwbuaWZcni"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # Data processing, Input & Output load\n",
    "\n",
    "import seaborn as sns  #Data visualisation\n",
    "\n",
    "import nltk # Natural Language Toolkit (statistical natural language processing (NLP) libraries )\n",
    "from nltk.stem.porter import *   # Stemming porterstemmer (not using lemmatizer)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings   # To avoid warning messages in the code run\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iMnDChB2cnpL"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d4b44183afb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_MR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Train Moview Reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_MR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.tsv'"
     ]
    }
   ],
   "source": [
    "train_MR = pd.read_csv(\"train.tsv\", sep=\"\\t\") # Train Moview Reviews \n",
    "test_MR = pd.read_csv(\"test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "CqdjzkWEcnsO",
    "outputId": "417c1031-d6d5-4d67-f87c-06504954183f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_MR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-03a3a1497185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train Data - '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_MR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_MR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_MR' is not defined"
     ]
    }
   ],
   "source": [
    "print('Train Data - ', train_MR.shape)\n",
    "train_MR.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2mhF2yucnvJ"
   },
   "outputs": [],
   "source": [
    "print('Test Data - ', test_MR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zp_ooIfTcny4"
   },
   "outputs": [],
   "source": [
    "train_MR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "cxbEWvedf35n",
    "outputId": "09e6470d-3690-4266-8057-19b7cb9ba979"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f01d222e748>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZFElEQVR4nO3df7AdZZ3n8fdHAoo/kCAZFpO4odaMVmRWhBTEYWecgTEERg1roQO1msiwZqoEV0d3Z3F3a7Ki1GrtjIw4ylRKIonrCgzqEl00k0XQXccAF0UQkOWKIkkBuRJ++GPFCvPdP85zJ8dwEy8dzjkJ9/2qOnW7v/1099OnNB+6+zndqSokSeriWaPugCRp/2WISJI6M0QkSZ0ZIpKkzgwRSVJns0bdgWE7/PDDa8GCBaPuhiTtN26++eYfV9WcqZbNuBBZsGABY2Njo+6GJO03kty7u2VezpIkdWaISJI6M0QkSZ0ZIpKkzgYaIkn+NMntSb6b5LNJnpPkqCQ3JBlPckWSg1rbZ7f58bZ8Qd923tfqdyU5pa++rNXGk5w/yGORJD3ZwEIkyVzg3wCLq+po4ADgTODDwEVV9VLgYeCctso5wMOtflFrR5JFbb1XAMuATyQ5IMkBwMeBU4FFwFmtrSRpSAZ9OWsWcHCSWcBzgfuBk4Cr2vJ1wOltenmbpy0/OUla/fKqeryqfgCMA8e3z3hV3VNVvwQub20lSUMysBCpqq3AXwA/ohcejwI3A49U1Y7WbAswt03PBe5r6+5o7V/UX99lnd3VJUlDMsjLWbPpnRkcBbwYeB69y1FDl2RVkrEkYxMTE6PogiQ9Iw3yF+t/APygqiYAknweOBE4NMmsdrYxD9ja2m8F5gNb2uWvFwIP9dUn9a+zu/qvqKo1wBqAxYsX+xYuTduJHztx1F0YiG+88xuj7oKeIQZ5T+RHwJIkz233Nk4G7gCuA85obVYCV7fpDW2etvyr1Xvt4gbgzDZ66yhgIXAjcBOwsI32OojezfcNAzweSdIuBnYmUlU3JLkK+BawA/g2vbOB/wlcnuSDrXZpW+VS4NNJxoHt9EKBqro9yZX0AmgHcG5VPQGQ5DxgI72RX2ur6vZBHY8k6ckG+gDGqloNrN6lfA+9kVW7tv0F8KbdbOdC4MIp6tcA1+x9TyVJXfiLdUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZwMLkSQvS3JL3+exJO9OcliSTUnubn9nt/ZJcnGS8SS3Jjm2b1srW/u7k6zsqx+X5La2zsXtXe6SpCEZWIhU1V1VdUxVHQMcB/wc+AJwPnBtVS0Erm3zAKcCC9tnFXAJQJLD6L1i9wR6r9VdPRk8rc3b+9ZbNqjjkSQ92bAuZ50MfL+q7gWWA+tafR1wepteDqyvns3AoUmOBE4BNlXV9qp6GNgELGvLDqmqzVVVwPq+bUmShmBYIXIm8Nk2fURV3d+mHwCOaNNzgfv61tnSanuqb5miLkkakoGHSJKDgDcAf7vrsnYGUUPow6okY0nGJiYmBr07SZoxhnEmcirwrap6sM0/2C5F0f5ua/WtwPy+9ea12p7q86aoP0lVramqxVW1eM6cOXt5OJKkScMIkbPYeSkLYAMwOcJqJXB1X31FG6W1BHi0XfbaCCxNMrvdUF8KbGzLHkuypI3KWtG3LUnSEMwa5MaTPA94LfAnfeUPAVcmOQe4F3hzq18DnAaM0xvJdTZAVW1P8gHgptbugqra3qbfAVwGHAx8uX0kSUMy0BCpqp8BL9ql9hC90Vq7ti3g3N1sZy2wdor6GHD009JZSdJT5i/WJUmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4GGiJJDk1yVZLvJbkzyauTHJZkU5K729/ZrW2SXJxkPMmtSY7t287K1v7uJCv76sclua2tc3GSDPJ4JEm/atBnIh8FvlJVLwdeCdwJnA9cW1ULgWvbPMCpwML2WQVcApDkMGA1cAJwPLB6Mnham7f3rbdswMcjSeozsBBJ8kLgd4FLAarql1X1CLAcWNearQNOb9PLgfXVsxk4NMmRwCnApqraXlUPA5uAZW3ZIVW1uaoKWN+3LUnSEAzyTOQoYAL4VJJvJ/lkkucBR1TV/a3NA8ARbXoucF/f+ltabU/1LVPUnyTJqiRjScYmJib28rAkSZMGGSKzgGOBS6rqVcDP2HnpCoB2BlED7MPkftZU1eKqWjxnzpxB706SZoxBhsgWYEtV3dDmr6IXKg+2S1G0v9va8q3A/L7157XanurzpqhLkoZkYCFSVQ8A9yV5WSudDNwBbAAmR1itBK5u0xuAFW2U1hLg0XbZayOwNMnsdkN9KbCxLXssyZI2KmtF37YkSUMwa8DbfyfwmSQHAfcAZ9MLriuTnAPcC7y5tb0GOA0YB37e2lJV25N8ALiptbugqra36XcAlwEHA19uH0nSkAw0RKrqFmDxFItOnqJtAefuZjtrgbVT1MeAo/eym5KkjvzFuiSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps4GGSJIfJrktyS1JxlrtsCSbktzd/s5u9SS5OMl4kluTHNu3nZWt/d1JVvbVj2vbH2/rZpDHI0n6VcM4E/n9qjqmqiZfk3s+cG1VLQSubfMApwIL22cVcAn0QgdYDZwAHA+sngye1ubtfestG/zhSJImjeJy1nJgXZteB5zeV19fPZuBQ5McCZwCbKqq7VX1MLAJWNaWHVJVm9v72df3bUuSNASDDpEC/i7JzUlWtdoRVXV/m34AOKJNzwXu61t3S6vtqb5livqTJFmVZCzJ2MTExN4cjySpz6wBb/9fVNXWJL8BbEryvf6FVVVJasB9oKrWAGsAFi9ePPD9SdJMMdAzkara2v5uA75A757Gg+1SFO3vttZ8KzC/b/V5rban+rwp6pKkIRlYiCR5XpIXTE4DS4HvAhuAyRFWK4Gr2/QGYEUbpbUEeLRd9toILE0yu91QXwpsbMseS7Kkjcpa0bctSdIQDPJy1hHAF9qo21nAf6+qryS5CbgyyTnAvcCbW/trgNOAceDnwNkAVbU9yQeAm1q7C6pqe5t+B3AZcDDw5faRJA3JwEKkqu4BXjlF/SHg5CnqBZy7m22tBdZOUR8Djt7rzkqSOvEX65KkzgwRSVJnhogkqTNDRJLU2bRCJMm106lJkmaWPY7OSvIc4LnA4e03GpNPyT2E3TxiRJI0c/y6Ib5/ArwbeDFwMztD5DHgrwfYL0nSfmCPIVJVHwU+muSdVfWxIfVJkrSfmNaPDavqY0l+G1jQv05VrR9QvyRJ+4FphUiSTwP/DLgFeKKVJ9/hIUmaoab72JPFwKL2aBJJkoDp/07ku8A/GWRHJEn7n+meiRwO3JHkRuDxyWJVvWEgvZIk7RemGyL/eZCdkCTtn6Y7Outrg+6IJGn/M93RWT+hNxoL4CDgQOBnVXXIoDomSdr3TfdM5AWT0+1VtMuBJYPqlCRp//CUn+JbPf8DOGU67ZMckOTbSb7U5o9KckOS8SRXJDmo1Z/d5sfb8gV923hfq9+V5JS++rJWG09y/lM9FknS3pnu5aw39s0+i97vRn4xzX28C7iT3kMbAT4MXFRVlyf5G+Ac4JL29+GqemmSM1u7P0qyCDgTeAW9Z3j9ryS/2bb1ceC1wBbgpiQbquqOafZLkrSXpnsm8vq+zynAT+hd0tqjJPOAPwQ+2eYDnARc1ZqsA05v08vbPG35yX2Xzi6vqser6gfAOHB8+4xX1T1V9Uvg8un0SZL09JnuPZGzO27/r4A/AybvqbwIeKSqdrT5Lex8pPxc4L62vx1JHm3t5wKb+7bZv859u9RPmKoTSVYBqwBe8pKXdDwUSdKupvtSqnlJvpBkW/t8rp1l7Gmd1wHbqurmp6Wne6Gq1lTV4qpaPGfOnFF3R5KeMaZ7OetTwAZ69yReDHyx1fbkROANSX5I71LTScBHgUOTTJ4BzQO2tumtwHyAtvyFwEP99V3W2V1dkjQk0w2ROVX1qara0T6XAXv8T/qqel9VzauqBfRujH+1qv4VcB1wRmu2Eri6TW9o87TlX20PfNwAnNlGbx0FLARuBG4CFrbRXge1fWyY5vFIkp4G0w2Rh5K8pQ3XPSDJW+idJXTx74H3JBmnd8/j0la/FHhRq78HOB+gqm4HrgTuAL4CnFtVT7T7KucBG+mN/rqytZUkDcl0n531x8DHgIvo/XL974G3TXcnVXU9cH2bvofeyKpd2/wCeNNu1r8QuHCK+jXANdPthyTp6TXdELkAWFlVDwMkOQz4C3rhIkmaoaZ7OeufTwYIQFVtB141mC5JkvYX0w2RZyWZPTnTzkSmexYjSXqGmm4Q/CXwzSR/2+bfxBT3KCRJM8t0f7G+PskYvd96ALzRZ1RJkqZ9SaqFhsEhSfpHT/lR8JIkTTJEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1Jm/Opc0LV/73deMugsD8Zqvf23UXdiveSYiSerMEJEkdWaISJI6M0QkSZ0NLESSPCfJjUm+k+T2JO9v9aOS3JBkPMkV7f3otHeoX9HqNyRZ0Let97X6XUlO6asva7XxJOcP6lgkSVMb5JnI48BJVfVK4BhgWZIlwIeBi6rqpcDDwDmt/TnAw61+UWtHkkXAmcArgGXAJybf9Q58HDgVWASc1dpKkoZkYCFSPT9tswe2T9F7nPxVrb4OOL1NL2/ztOUnJ0mrX15Vj1fVD4Bxeu9oPx4Yr6p7quqXwOWtrSRpSAZ6T6SdMdwCbAM2Ad8HHqmqHa3JFmBum54L3AfQlj8KvKi/vss6u6tP1Y9VScaSjE1MTDwdhyZJYsAhUlVPVNUxwDx6Zw4vH+T+9tCPNVW1uKoWz5kzZxRdkKRnpKGMzqqqR4DrgFcDhyaZ/KX8PGBrm94KzAdoy18IPNRf32Wd3dUlSUMyyNFZc5Ic2qYPBl4L3EkvTM5ozVYCV7fpDW2etvyrVVWtfmYbvXUUsBC4EbgJWNhGex1E7+b7hkEdjyTpyQb57KwjgXVtFNWzgCur6ktJ7gAuT/JB4NvApa39pcCnk4wD2+mFAlV1e5Ir6b2adwdwblU9AZDkPGAjcACwtqpuH+DxSJJ2MbAQqapbgVdNUb+H3v2RXeu/AN60m21dCFw4Rf0a4Jq97qwkqRN/sS5J6sxHwetJfnTBb426CwPxkj+/bdRdkJ5xPBORJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1Nkg37E+P8l1Se5IcnuSd7X6YUk2Jbm7/Z3d6klycZLxJLcmObZvWytb+7uTrOyrH5fktrbOxUkyqOORJD3ZIM9EdgDvrapFwBLg3CSLgPOBa6tqIXBtmwc4FVjYPquAS6AXOsBq4AR6r9VdPRk8rc3b+9ZbNsDjkSTtYmAhUlX3V9W32vRPgDuBucByYF1rtg44vU0vB9ZXz2bg0CRHAqcAm6pqe1U9DGwClrVlh1TV5qoqYH3ftiRJQzCUeyJJFgCvAm4Ajqiq+9uiB4Aj2vRc4L6+1ba02p7qW6aoT7X/VUnGkoxNTEzs1bFIknYaeIgkeT7wOeDdVfVY/7J2BlGD7kNVramqxVW1eM6cOYPenSTNGAMNkSQH0guQz1TV51v5wXYpivZ3W6tvBeb3rT6v1fZUnzdFXZI0JIMcnRXgUuDOqvpI36INwOQIq5XA1X31FW2U1hLg0XbZayOwNMnsdkN9KbCxLXssyZK2rxV925IkDcGsAW77ROCtwG1Jbmm1/wB8CLgyyTnAvcCb27JrgNOAceDnwNkAVbU9yQeAm1q7C6pqe5t+B3AZcDDw5faRJA3JwEKkqv4PsLvfbZw8RfsCzt3NttYCa6eojwFH70U3JUl7wV+sS5I6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6G+Q71tcm2Zbku321w5JsSnJ3+zu71ZPk4iTjSW5NcmzfOitb+7uTrOyrH5fktrbOxe0965KkIRrkmchlwLJdaucD11bVQuDaNg9wKrCwfVYBl0AvdIDVwAnA8cDqyeBpbd7et96u+5IkDdjAQqSqvg5s36W8HFjXptcBp/fV11fPZuDQJEcCpwCbqmp7VT0MbAKWtWWHVNXm9m729X3bkiQNybDviRxRVfe36QeAI9r0XOC+vnZbWm1P9S1T1KeUZFWSsSRjExMTe3cEkqR/NLIb6+0Mooa0rzVVtbiqFs+ZM2cYu5SkGWHWkPf3YJIjq+r+dklqW6tvBeb3tZvXaluB39ulfn2rz5uivSQN3F+/94uj7sJAnPeXr3/K6wz7TGQDMDnCaiVwdV99RRultQR4tF322ggsTTK73VBfCmxsyx5LsqSNylrRty1J0pAM7EwkyWfpnUUcnmQLvVFWHwKuTHIOcC/w5tb8GuA0YBz4OXA2QFVtT/IB4KbW7oKqmrxZ/w56I8AOBr7cPpKkIRpYiFTVWbtZdPIUbQs4dzfbWQusnaI+Bhy9N32UJO0df7EuSeps2DfW91nH/bv1o+7CQNz8X1eMuguSnsE8E5EkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzgwRSVJnhogkqTNDRJLU2X4fIkmWJbkryXiS80fdH0maSfbrEElyAPBx4FRgEXBWkkWj7ZUkzRz7dYgAxwPjVXVPVf0SuBxYPuI+SdKMkaoadR86S3IGsKyq/nWbfytwQlWdt0u7VcCqNvsy4K6hdvTJDgd+POI+7Cv8Lnbyu9jJ72KnfeG7+KdVNWeqBTPiHetVtQZYM+p+TEoyVlWLR92PfYHfxU5+Fzv5Xey0r38X+/vlrK3A/L75ea0mSRqC/T1EbgIWJjkqyUHAmcCGEfdJkmaM/fpyVlXtSHIesBE4AFhbVbePuFvTsc9cWtsH+F3s5Hexk9/FTvv0d7Ff31iXJI3W/n45S5I0QoaIJKkzQ2TIfExLT5K1SbYl+e6o+zJqSeYnuS7JHUluT/KuUfdpVJI8J8mNSb7Tvov3j7pPo5TkgCTfTvKlUfdldwyRIfIxLb/iMmDZqDuxj9gBvLeqFgFLgHNn8P8uHgdOqqpXAscAy5IsGXGfRuldwJ2j7sSeGCLD5WNamqr6OrB91P3YF1TV/VX1rTb9E3r/aMwdba9Go3p+2mYPbJ8ZOfonyTzgD4FPjrove2KIDNdc4L6++S3M0H8sNLUkC4BXATeMtiej0y7h3AJsAzZV1Uz9Lv4K+DPgH0bdkT0xRKR9RJLnA58D3l1Vj426P6NSVU9U1TH0nkBxfJKjR92nYUvyOmBbVd086r78OobIcPmYFk0pyYH0AuQzVfX5UfdnX1BVjwDXMTPvnZ0IvCHJD+ld9j4pyX8bbZemZogMl49p0ZMkCXApcGdVfWTU/RmlJHOSHNqmDwZeC3xvtL0avqp6X1XNq6oF9P6d+GpVvWXE3ZqSITJEVbUDmHxMy53AlfvJY1qedkk+C3wTeFmSLUnOGXWfRuhE4K30/mvzlvY5bdSdGpEjgeuS3ErvP7o2VdU+O7xVPvZEkrQXPBORJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aINE1J/mN7suytbRjuCR22cUz/8N0kbxj005yT/F6S3x7kPjRz7devx5WGJcmrgdcBx1bV40kOBw7qsKljgMXANQBVtYHB/+D094CfAn8/4P1oBvJ3ItI0JHkjcHZVvX6X+nHAR4DnAz8G3lZV9ye5nt5DFH8fOBQ4p82PAwfTe9zNf2nTi6vqvCSXAf+P3gMYfwP4Y2AF8Grghqp6W9vnUuD9wLOB77d+/bQ9ImMd8Hp6T799E/ALYDPwBDABvLOq/vfT++1oJvNyljQ9fwfMT/J/k3wiyWva864+BpxRVccBa4EL+9aZVVXHA+8GVrfH//85cEVVHVNVV0yxn9n0QuNP6Z2hXAS8AvitdinscOA/AX9QVccCY8B7+tb/catfAvzbqvoh8DfARW2fBoieVl7Okqah/Zf+ccDv0Du7uAL4IHA0sKn3+CsOAO7vW23yQYo3AwumuasvVlUluQ14sKpuA0hye9vGPHovNPtG2+dB9B4fM9U+3zj9I5S6MUSkaaqqJ4DrgevbP/LnArdX1at3s8rj7e8TTP//a5Pr/EPf9OT8rLatTVV11tO4T6kzL2dJ05DkZUkW9pWOofcQzTntpjtJDkzyil+zqZ8AL9iLrmwGTkzy0rbP5yX5zQHvU9otQ0SanucD65Lc0Z4wu4je/Y0zgA8n+Q5wC/DrhtJeByxqQ4T/6Kl2oqomgLcBn239+Cbw8l+z2heBf9n2+TtPdZ/Snjg6S5LUmWcikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjr7//FdrjUoLUFVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=train_MR, x='Sentiment') # bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNvPRQPDf38K",
    "outputId": "97db9995-bb4c-44d8-f6df-a4387b7cf2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "0     7072\n",
      "1    27273\n",
      "2    79582\n",
      "3    32927\n",
      "4     9206\n",
      "dtype: int64\n",
      "Sentiment\n",
      "0     4.53\n",
      "1    17.48\n",
      "2    50.99\n",
      "3    21.10\n",
      "4     5.90\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dist = train_MR.groupby([\"Sentiment\"]).size() # groupby helps in getting the counts of unique items\n",
    "print(dist)\n",
    "\n",
    "dist_Percentage = round((dist / dist.sum())*100, 2)\n",
    "print(dist_Percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpukS5kiO-fC"
   },
   "outputs": [],
   "source": [
    "# Python community that try not to use for loops with pd df\n",
    "# intead of using for i in train_MR['Phrase']\n",
    "# use .apply(pass a function) --> much more efficient way than for loop to deal with pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "xjelNGrLf3-4",
    "outputId": "79677ee9-fd16-49dd-8e56-cf1cda81cf5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length  \n",
       "0          1      37  \n",
       "1          2      14  \n",
       "2          2       2  \n",
       "3          2       1  \n",
       "4          2       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MR['Length'] = train_MR['Phrase'].apply(lambda x: len(str(x).split(' ')))   ## Will get the length of each phrase \n",
    "test_MR['Length'] = test_MR['Phrase'].apply(lambda x: len(str(x).split(' '))) \n",
    "# .apply pd df --> .apply(has to be a function), python def sum():, this function gets applied to every item in pd df\n",
    "# this is like a for loop on every item on the pd df to the functions task\n",
    "\n",
    "# Just as you have single line loop in python, similarly you have single line functions in python known as lambda functions.\n",
    "train_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0tbhWaE5Qg4"
   },
   "outputs": [],
   "source": [
    "train_MR['Length'] = 0\n",
    "train_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPV0H1B2QQy9"
   },
   "outputs": [],
   "source": [
    "s = 'A good bat'\n",
    "s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "nSarKBQr5QtJ",
    "outputId": "7e07e2bc-b26e-4e10-e5d8-e2988cc99138"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length  \n",
       "0          1      37  \n",
       "1          2      14  \n",
       "2          2       2  \n",
       "3          2       1  \n",
       "4          2       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda x: len(str(x).split(' ')) so this single line lambda function does the exact same work as the below 2 lines.\n",
    "# single line lambda function is a python functionality just like single line for loop\n",
    "# lambda has a specific meaning in python just like print has a specific meaning in python\n",
    "def return_length(x):\n",
    "    return len(str(x).split(' '))\n",
    "\n",
    "return_length('this series') # sending data to the function\n",
    "\n",
    "train_MR['Length'] = train_MR['Phrase'].apply(return_length)\n",
    "# sending the function to the data, but still data has to pass through function to get processed like before\n",
    "# opeartion-wise there is nothing new or different only the coding method has changed\n",
    "# this way of coding method where we send the function to the data is called functional programming\n",
    "# big-data, pySpark, Hive, Hadoop, scala, haskell  --> functional programming coding method\n",
    "train_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orGgMMAdVtP2"
   },
   "outputs": [],
   "source": [
    "for i in range(train_MR.shape[0]):\n",
    "    train_MR.iloc[i, 4] = 0\n",
    "train_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXnEhqBURkOg"
   },
   "outputs": [],
   "source": [
    "train_MR['Length'] = 0 # entire column operations are encouraged in pd df\n",
    "train_MR.head() # loop in pd df becomes very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZWbo14oYRf4"
   },
   "outputs": [],
   "source": [
    "for i in range(train_MR.shape[0]):\n",
    "    train_MR.iloc[i, 4] = len(str(train_MR.iloc[i, 2]).split(' '))\n",
    "train_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2PqRlLhf4Bk",
    "outputId": "92390037-1a64-4149-ec36-6fbaf0b416b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "Length        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MR.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB9naV8kf4Ep",
    "outputId": "2db6de56-41db-4340-dac7-e84329422372"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Length        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_MR.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwiIuz0gf4HW"
   },
   "outputs": [],
   "source": [
    "train_MR['cat'] = 'TRAIN'\n",
    "test_MR['cat'] = 'TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "HEsXpEu0zENT",
    "outputId": "5068b113-ea19-48ae-a6c9-cf8c3d850aa4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length    cat  \n",
       "0          1      37  TRAIN  \n",
       "1          2      14  TRAIN  \n",
       "2          2       2  TRAIN  \n",
       "3          2       1  TRAIN  \n",
       "4          2       1  TRAIN  "
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "eGF4a56NzLjY",
    "outputId": "7ba4f0bc-deb8-48af-fe0f-940e5b37dd67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>8</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>1</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>6</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "   Length   cat  \n",
       "0       8  TEST  \n",
       "1       7  TEST  \n",
       "2       1  TEST  \n",
       "3       6  TEST  \n",
       "4       5  TEST  "
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_MR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "tM4FUmKPf5KW",
    "outputId": "3b125f03-04e5-4be0-a17c-4771ef195e43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length    cat  \n",
       "0        1.0      37  TRAIN  \n",
       "1        2.0      14  TRAIN  \n",
       "2        2.0       2  TRAIN  \n",
       "3        2.0       1  TRAIN  \n",
       "4        2.0       1  TRAIN  "
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test = train_MR.append(test_MR, ignore_index=True) # Theoretically this is not encouraged,for example and learning purposes, but in reality we are not supposed to that\n",
    "#combining both the train and test to process their columns together\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "sBuknxtYNA6n",
    "outputId": "4840b6a3-c3e3-4e99-f4d9-d26cd39c2733"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222347</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222348</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222349</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222350</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222351</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                                  Phrase  \\\n",
       "222347    222348       11855  A long-winded , predictable scenario .   \n",
       "222348    222349       11855    A long-winded , predictable scenario   \n",
       "222349    222350       11855                         A long-winded ,   \n",
       "222350    222351       11855                           A long-winded   \n",
       "222351    222352       11855                    predictable scenario   \n",
       "\n",
       "        Sentiment  Length   cat  \n",
       "222347        NaN       6  TEST  \n",
       "222348        NaN       5  TEST  \n",
       "222349        NaN       3  TEST  \n",
       "222350        NaN       2  TEST  \n",
       "222351        NaN       2  TEST  "
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "wVySSbvuNGaq",
    "outputId": "dac070e9-dd0b-475c-b95e-a6a31aaa0381"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                     Phrase  Sentiment  Length  \\\n",
       "156055    156056        8544                  Hearst 's          2       2   \n",
       "156056    156057        8544  forced avuncular chortles          1       3   \n",
       "156057    156058        8544         avuncular chortles          3       2   \n",
       "156058    156059        8544                  avuncular          2       1   \n",
       "156059    156060        8544                   chortles          2       1   \n",
       "\n",
       "          cat  \n",
       "156055  TRAIN  \n",
       "156056  TRAIN  \n",
       "156057  TRAIN  \n",
       "156058  TRAIN  \n",
       "156059  TRAIN  "
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MR.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "e2FhrphPNMEj",
    "outputId": "06e3bc1f-368a-4266-d60b-a5b44fea4694"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>6</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>3</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>2</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                  Phrase  Length  \\\n",
       "66287    222348       11855  A long-winded , predictable scenario .       6   \n",
       "66288    222349       11855    A long-winded , predictable scenario       5   \n",
       "66289    222350       11855                         A long-winded ,       3   \n",
       "66290    222351       11855                           A long-winded       2   \n",
       "66291    222352       11855                    predictable scenario       2   \n",
       "\n",
       "        cat  \n",
       "66287  TEST  \n",
       "66288  TEST  \n",
       "66289  TEST  \n",
       "66290  TEST  \n",
       "66291  TEST  "
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_MR.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm4jfYXFNSBp",
    "outputId": "a5152730-5669-4adc-862e-9a00c36985bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222351"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "156059+66292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "5SPEJ7ESht5Q",
    "outputId": "6bdc2439-9a69-4e53-c46e-59bdc50e72ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "      <th>PreProcess_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length    cat                                PreProcess_Sentence  \n",
       "0        1.0      37  TRAIN  A series of escapades demonstrating the adage ...  \n",
       "1        2.0      14  TRAIN  A series of escapades demonstrating the adage ...  \n",
       "2        2.0       2  TRAIN                                           A series  \n",
       "3        2.0       1  TRAIN                                                  A  \n",
       "4        2.0       1  TRAIN                                             series  "
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['PreProcess_Sentence'] = train_test['Phrase'].str.replace(\"[^a-zA-Z#]\", \" \") #RegEx to remove punctuation\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxVw-bhiht8U"
   },
   "outputs": [],
   "source": [
    "train_test['PreProcess_Sentence'] = train_test['PreProcess_Sentence'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# fancy python -- function, for, if, list --> all in 1 line\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Mq6XjhN6A6l"
   },
   "outputs": [],
   "source": [
    "train_test['PreProcess_Sentence'] = train_test['Phrase'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaaMHdbsC05x",
    "outputId": "29869f28-16cc-4ca3-ee86-9c874384ba46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abra', 'ca', 'dabra']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 'abra ca dabra'\n",
    "temp.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIu89K7YC8GB"
   },
   "outputs": [],
   "source": [
    "' '.join(['abra', 'ca', 'dabra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1FqY7RpEpMt"
   },
   "outputs": [],
   "source": [
    "' '.join(['abra', '', 'dabra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSpY0VbaFOPu"
   },
   "outputs": [],
   "source": [
    "' '.join([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6q0CfQWFS4r"
   },
   "outputs": [],
   "source": [
    "' '.join([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "7Dm63lDlDKZj",
    "outputId": "4b0afd90-2b18-4936-8430-c6db10218869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abra', 'dabra']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'abra dabra'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [] # empty list\n",
    "for w in 'abra ca dabra'.split(): # for w in list ['abra', 'ca', 'dabra'], 'cat, 'hen', 'the', 'how'\n",
    "    if len(w)>3:\n",
    "        temp.append(w)\n",
    "print(temp)\n",
    "' '.join(temp) # complete opposite .split()\n",
    "# .split() takes a string and returns a list of space-separated word\n",
    "# .join() takes alist of words and returns a space-separated string of those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "x39Z2edr6BC5",
    "outputId": "eeeb8e35-0512-45a5-ea2b-470a03a98f26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "      <th>PreProcess_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series escapades demonstrating adage that what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series escapades demonstrating adage that what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length    cat                                PreProcess_Sentence  \n",
       "0        1.0      37  TRAIN  series escapades demonstrating adage that what...  \n",
       "1        2.0      14  TRAIN  series escapades demonstrating adage that what...  \n",
       "2        2.0       2  TRAIN                                             series  \n",
       "3        2.0       1  TRAIN                                                     \n",
       "4        2.0       1  TRAIN                                             series  "
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence(x):\n",
    "    temp = []\n",
    "    for w in x.split():\n",
    "        if len(w)>3:\n",
    "            temp.append(w)\n",
    "    return ' '.join(temp)\n",
    "\n",
    "train_test['PreProcess_Sentence'] = train_test['PreProcess_Sentence'].apply(preprocess_sentence)\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdGCd1mkht_a",
    "outputId": "6969c6e3-14ff-49fe-996e-843256722a9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    series escapades demonstrating adage that what...\n",
       "1    series escapades demonstrating adage that what...\n",
       "2                                               series\n",
       "3                                                     \n",
       "4                                               series\n",
       "Name: PreProcess_Sentence, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['PreProcess_Sentence'] = train_test['PreProcess_Sentence'].str.lower()\n",
    "train_test['PreProcess_Sentence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrBhoiNfhuCE",
    "outputId": "dba7ab6b-449c-4da0-8c3d-f67c8ca6ebad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [series, escapades, demonstrating, adage, that...\n",
       "1    [series, escapades, demonstrating, adage, that...\n",
       "2                                             [series]\n",
       "3                                                   []\n",
       "4                                             [series]\n",
       "Name: tokenized_words, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['tokenized_words'] = train_test['PreProcess_Sentence'].apply(lambda x: x.split())\n",
    "train_test.tokenized_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "x6zGnS6655Hq",
    "outputId": "3ba994ef-c0f7-4e4a-c66c-511ea440707d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "      <th>PreProcess_Sentence</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series escapades demonstrating adage that what...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series escapades demonstrating adage that what...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length    cat  \\\n",
       "0        1.0      37  TRAIN   \n",
       "1        2.0      14  TRAIN   \n",
       "2        2.0       2  TRAIN   \n",
       "3        2.0       1  TRAIN   \n",
       "4        2.0       1  TRAIN   \n",
       "\n",
       "                                 PreProcess_Sentence  \\\n",
       "0  series escapades demonstrating adage that what...   \n",
       "1  series escapades demonstrating adage that what...   \n",
       "2                                             series   \n",
       "3                                                      \n",
       "4                                             series   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0  [series, escapades, demonstrating, adage, that...  \n",
       "1  [series, escapades, demonstrating, adage, that...  \n",
       "2                                           [series]  \n",
       "3                                                 []  \n",
       "4                                           [series]  "
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZlURbUeHHUw",
    "outputId": "b6d625ce-0163-4a5d-f527-61bd7111f1c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [series, escapades, demonstrating, adage, that...\n",
       "1    [series, escapades, demonstrating, adage, that...\n",
       "2                                             [series]\n",
       "3                                                   []\n",
       "4                                             [series]\n",
       "Name: tokenized_words, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['tokenized_words'].head()\n",
    "# train_test.tokenized_words.head(). # Both these code lines are doing the exact same thing, just different ways of writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_KBdomwhuFB",
    "outputId": "a68e1d3a-aa87-4e3a-e73e-c13a9adc8fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [seri, escapad, demonstr, adag, that, what, go...\n",
      "1    [seri, escapad, demonstr, adag, that, what, go...\n",
      "2                                               [seri]\n",
      "3                                                   []\n",
      "4                                               [seri]\n",
      "Name: tokenized_words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stemming = PorterStemmer() # stemming\n",
    "# nltk 2 types of stemmers - porter stemmer, snowball stemmer \n",
    "train_test['tokenized_words'] = train_test.tokenized_words.apply(lambda x: [stemming.stem(i) for i in x]) # stemming\n",
    "#stemming.stem(word)\n",
    "print(train_test.tokenized_words.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "1AqvYwrFhuIg",
    "outputId": "731ab7f0-2641-4dfd-ad9e-4ffa1e547c0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>cat</th>\n",
       "      <th>PreProcess_Sentence</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series escapades demonstrating adage that what...</td>\n",
       "      <td>[seri, escapad, demonstr, adag, that, what, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series escapades demonstrating adage that what...</td>\n",
       "      <td>[seri, escapad, demonstr, adag, that, what, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "      <td>[seri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>series</td>\n",
       "      <td>[seri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Length    cat  \\\n",
       "0        1.0      37  TRAIN   \n",
       "1        2.0      14  TRAIN   \n",
       "2        2.0       2  TRAIN   \n",
       "3        2.0       1  TRAIN   \n",
       "4        2.0       1  TRAIN   \n",
       "\n",
       "                                 PreProcess_Sentence  \\\n",
       "0  series escapades demonstrating adage that what...   \n",
       "1  series escapades demonstrating adage that what...   \n",
       "2                                             series   \n",
       "3                                                      \n",
       "4                                             series   \n",
       "\n",
       "                                     tokenized_words  \n",
       "0  [seri, escapad, demonstr, adag, that, what, go...  \n",
       "1  [seri, escapad, demonstr, adag, that, what, go...  \n",
       "2                                             [seri]  \n",
       "3                                                 []  \n",
       "4                                             [seri]  "
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cyZc7ivhuLI",
    "outputId": "f281c066-f6fa-4e97-da5b-af1148588bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "corpus = train_test.PreProcess_Sentence  ## Collection of documents \n",
    "vectorizer = TfidfVectorizer(stop_words='english', analyzer='word')\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XevYoZ1wM1bv"
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "my6GnHKJO8LJ",
    "outputId": "016cf91b-c034-4759-9ef8-823cc8f072da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222352, 16726)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75MX8YycNno0",
    "outputId": "8920d72e-2c7d-4b79-df81-8ad41a85e56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.42164973 10.74707213  9.1531384  ... 10.53943277 10.36758251\n",
      " 11.52026202]\n"
     ]
    }
   ],
   "source": [
    "idf = vectorizer.idf_\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmj08odWNo_u",
    "outputId": "98dc2326-be00-432d-ad6f-6db07099eecd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'series': 12997,\n",
       " 'escapades': 4937,\n",
       " 'demonstrating': 3726,\n",
       " 'adage': 156,\n",
       " 'good': 6302,\n",
       " 'goose': 6318,\n",
       " 'gander': 6053,\n",
       " 'occasionally': 10033,\n",
       " 'amuses': 487,\n",
       " 'amounts': 478,\n",
       " 'story': 14152,\n",
       " 'quiet': 11572,\n",
       " 'introspective': 7786,\n",
       " 'entertaining': 4845,\n",
       " 'independent': 7435,\n",
       " 'worth': 16583,\n",
       " 'seeking': 12906,\n",
       " 'fans': 5337,\n",
       " 'ismail': 7871,\n",
       " 'merchant': 9202,\n",
       " 'work': 16553,\n",
       " 'suspect': 14516,\n",
       " 'hard': 6672,\n",
       " 'time': 15005,\n",
       " 'sitting': 13346,\n",
       " 'positively': 11036,\n",
       " 'thrilling': 14950,\n",
       " 'combination': 2686,\n",
       " 'ethnography': 4983,\n",
       " 'intrigue': 7773,\n",
       " 'betrayal': 1304,\n",
       " 'deceit': 3560,\n",
       " 'murder': 9630,\n",
       " 'shakespearean': 13072,\n",
       " 'tragedy': 15166,\n",
       " 'juicy': 8054,\n",
       " 'soap': 13589,\n",
       " 'opera': 10123,\n",
       " 'aggressive': 310,\n",
       " 'self': 12929,\n",
       " 'glorification': 6252,\n",
       " 'manipulative': 8941,\n",
       " 'whitewash': 16392,\n",
       " 'comedy': 2702,\n",
       " 'drama': 4335,\n",
       " 'nearly': 9769,\n",
       " 'epic': 4888,\n",
       " 'proportions': 11365,\n",
       " 'rooted': 12456,\n",
       " 'performance': 10627,\n",
       " 'title': 15040,\n",
       " 'character': 2230,\n",
       " 'undergoing': 15541,\n",
       " 'midlife': 9269,\n",
       " 'crisis': 3287,\n",
       " 'narratively': 9726,\n",
       " 'trouble': 15322,\n",
       " 'plodding': 10893,\n",
       " 'mess': 9222,\n",
       " 'importance': 7334,\n",
       " 'earnest': 4512,\n",
       " 'plays': 10866,\n",
       " 'like': 8554,\n",
       " 'reading': 11739,\n",
       " 'bartlett': 1118,\n",
       " 'familiar': 5317,\n",
       " 'quotations': 11594,\n",
       " 'does': 4218,\n",
       " 'leave': 8425,\n",
       " 'hate': 6714,\n",
       " 'reason': 11764,\n",
       " 'little': 8626,\n",
       " 'recommend': 11813,\n",
       " 'snow': 13581,\n",
       " 'dogs': 4226,\n",
       " 'unless': 15713,\n",
       " 'considers': 2951,\n",
       " 'cliched': 2518,\n",
       " 'dialogue': 3904,\n",
       " 'perverse': 10684,\n",
       " 'escapism': 4942,\n",
       " 'source': 13714,\n",
       " 'high': 6881,\n",
       " 'hilarity': 6899,\n",
       " 'kung': 8247,\n",
       " 'oedekerk': 10055,\n",
       " 'realization': 11753,\n",
       " 'childhood': 2335,\n",
       " 'dream': 4362,\n",
       " 'martial': 9005,\n",
       " 'arts': 757,\n",
       " 'flick': 5665,\n",
       " 'proves': 11390,\n",
       " 'dreams': 4368,\n",
       " 'youth': 16679,\n",
       " 'remain': 12021,\n",
       " 'just': 8076,\n",
       " 'performances': 10628,\n",
       " 'absolute': 36,\n",
       " 'fresnadillo': 5906,\n",
       " 'ways': 16266,\n",
       " 'extravagant': 5225,\n",
       " 'chance': 2212,\n",
       " 'distort': 4149,\n",
       " 'perspective': 10676,\n",
       " 'throw': 14958,\n",
       " 'path': 10507,\n",
       " 'sense': 12952,\n",
       " 'moonlight': 9498,\n",
       " 'mile': 9285,\n",
       " 'better': 1309,\n",
       " 'judgment': 8043,\n",
       " 'damned': 3446,\n",
       " 'welcome': 16329,\n",
       " 'relief': 12007,\n",
       " 'baseball': 1120,\n",
       " 'movies': 9594,\n",
       " 'mythic': 9683,\n",
       " 'sweet': 14558,\n",
       " 'modest': 9432,\n",
       " 'ultimately': 15440,\n",
       " 'winning': 16468,\n",
       " 'bilingual': 1343,\n",
       " 'charmer': 2258,\n",
       " 'woman': 16520,\n",
       " 'inspired': 7636,\n",
       " 'dizzily': 4194,\n",
       " 'gorgeous': 6326,\n",
       " 'companion': 2751,\n",
       " 'wong': 16534,\n",
       " 'mood': 9492,\n",
       " 'love': 8734,\n",
       " 'hong': 7000,\n",
       " 'kong': 8227,\n",
       " 'movie': 9586,\n",
       " 'despite': 3832,\n",
       " 'mainland': 8866,\n",
       " 'setting': 13024,\n",
       " 'inept': 7488,\n",
       " 'screen': 12821,\n",
       " 'remakes': 12027,\n",
       " 'avengers': 938,\n",
       " 'wild': 16418,\n",
       " 'west': 16347,\n",
       " 'expect': 5131,\n",
       " 'best': 1298,\n",
       " 'indie': 7447,\n",
       " 'year': 16653,\n",
       " 'hatfield': 6718,\n",
       " 'hicks': 6870,\n",
       " 'make': 8882,\n",
       " 'oddest': 10045,\n",
       " 'couples': 3160,\n",
       " 'study': 14258,\n",
       " 'gambles': 6044,\n",
       " 'publishing': 11439,\n",
       " 'world': 16568,\n",
       " 'offering': 10066,\n",
       " 'case': 2099,\n",
       " 'exists': 5122,\n",
       " 'apart': 600,\n",
       " 'political': 10962,\n",
       " 'ramifications': 11655,\n",
       " 'going': 6287,\n",
       " 'house': 7082,\n",
       " 'party': 10470,\n",
       " 'watching': 16247,\n",
       " 'host': 7063,\n",
       " 'defend': 3619,\n",
       " 'frothing': 5945,\n",
       " 'girlfriend': 6208,\n",
       " 'chuck': 2404,\n",
       " 'norris': 9914,\n",
       " 'grenade': 6438,\n",
       " 'occurs': 10040,\n",
       " 'times': 15014,\n",
       " 'windtalkers': 16456,\n",
       " 'indication': 7444,\n",
       " 'minded': 9310,\n",
       " 'film': 5530,\n",
       " 'plot': 10896,\n",
       " 'romantic': 12437,\n",
       " 'boilerplate': 1542,\n",
       " 'start': 14003,\n",
       " 'finish': 5562,\n",
       " 'arrives': 728,\n",
       " 'impeccable': 7307,\n",
       " 'pedigree': 10572,\n",
       " 'mongrel': 9463,\n",
       " 'indecipherable': 7431,\n",
       " 'complications': 2801,\n",
       " 'clearly': 2500,\n",
       " 'means': 9116,\n",
       " 'preach': 11106,\n",
       " 'exclusively': 5084,\n",
       " 'converted': 3060,\n",
       " 'offers': 10068,\n",
       " 'opportunities': 10135,\n",
       " 'occasional': 10032,\n",
       " 'smiles': 13526,\n",
       " 'chuckles': 2406,\n",
       " 'theater': 14867,\n",
       " 'wilde': 16420,\n",
       " 'actors': 145,\n",
       " 'latest': 8352,\n",
       " 'vapid': 15930,\n",
       " 'actor': 141,\n",
       " 'exercise': 5097,\n",
       " 'appropriate': 651,\n",
       " 'structure': 14232,\n",
       " 'arthur': 739,\n",
       " 'schnitzler': 12759,\n",
       " 'reigen': 11952,\n",
       " 'vaudeville': 15947,\n",
       " 'constructed': 2974,\n",
       " 'narrative': 9725,\n",
       " 'terms': 14824,\n",
       " 'inoffensive': 7594,\n",
       " 'actually': 152,\n",
       " 'action': 132,\n",
       " 'hampered': 6618,\n",
       " 'paralyzed': 10421,\n",
       " 'indulgent': 7477,\n",
       " 'script': 12837,\n",
       " 'aims': 340,\n",
       " 'poetry': 10931,\n",
       " 'ends': 4770,\n",
       " 'sounding': 13708,\n",
       " 'satire': 12662,\n",
       " 'computer': 2823,\n",
       " 'generated': 6121,\n",
       " 'feature': 5419,\n",
       " 'cartoon': 2090,\n",
       " 'feel': 5429,\n",
       " 'makes': 8885,\n",
       " 'glacial': 6215,\n",
       " 'pacing': 10341,\n",
       " 'early': 4508,\n",
       " 'makers': 8884,\n",
       " 'serve': 13008,\n",
       " 'cliches': 2519,\n",
       " 'considerable': 2946,\n",
       " 'dash': 3490,\n",
       " 'cattaneo': 2143,\n",
       " 'followed': 5742,\n",
       " 'runaway': 12526,\n",
       " 'success': 14362,\n",
       " 'monty': 9489,\n",
       " 'different': 3934,\n",
       " 'unnamed': 15732,\n",
       " 'easily': 4526,\n",
       " 'substitutable': 14341,\n",
       " 'forces': 5771,\n",
       " 'terror': 14836,\n",
       " 'heroes': 6854,\n",
       " 'horror': 7053,\n",
       " 'avoid': 949,\n",
       " 'feels': 5433,\n",
       " 'interested': 7712,\n",
       " 'amusing': 488,\n",
       " 'progression': 11323,\n",
       " 'rambling': 11651,\n",
       " 'incoherence': 7408,\n",
       " 'gives': 6213,\n",
       " 'meaning': 9112,\n",
       " 'phrase': 10740,\n",
       " 'fatal': 5378,\n",
       " 'error': 4931,\n",
       " 'judge': 8040,\n",
       " 'soon': 13672,\n",
       " 'dark': 3481,\n",
       " 'gritty': 6470,\n",
       " 'takes': 14651,\n",
       " 'totally': 15122,\n",
       " 'unexpected': 15627,\n",
       " 'directions': 3984,\n",
       " 'keeps': 8127,\n",
       " 'young': 16675,\n",
       " 'romantics': 12442,\n",
       " 'date': 3493,\n",
       " 'tartakovsky': 14695,\n",
       " 'team': 14731,\n",
       " 'freakish': 5873,\n",
       " 'powers': 11085,\n",
       " 'visual': 16100,\n",
       " 'charm': 2257,\n",
       " 'writers': 16617,\n",
       " 'slip': 13463,\n",
       " 'modern': 9428,\n",
       " 'banality': 1061,\n",
       " 'vincent': 16065,\n",
       " 'gallo': 6040,\n",
       " 'right': 12339,\n",
       " 'home': 6981,\n",
       " 'french': 5893,\n",
       " 'shocker': 13170,\n",
       " 'playing': 10863,\n",
       " 'usual': 15889,\n",
       " 'weirdo': 16326,\n",
       " 'role': 12421,\n",
       " 'primary': 11231,\n",
       " 'goal': 6272,\n",
       " 'frighten': 5924,\n",
       " 'disturb': 4162,\n",
       " 'works': 16565,\n",
       " 'spectacularly': 13773,\n",
       " 'shiver': 13164,\n",
       " 'inducing': 7472,\n",
       " 'nerve': 9809,\n",
       " 'rattling': 11710,\n",
       " 'ride': 12325,\n",
       " 'minute': 9335,\n",
       " 'minutes': 9337,\n",
       " 'decent': 3564,\n",
       " 'material': 9054,\n",
       " 'fortunately': 5822,\n",
       " 'option': 10151,\n",
       " 'sensational': 12949,\n",
       " 'true': 15331,\n",
       " 'crime': 3277,\n",
       " 'hell': 6820,\n",
       " 'jaunt': 7941,\n",
       " 'purists': 11494,\n",
       " 'experimental': 5148,\n",
       " 'storytelling': 14157,\n",
       " 'horrifying': 7051,\n",
       " 'tricky': 15277,\n",
       " 'satisfying': 12671,\n",
       " 'david': 3503,\n",
       " 'mamet': 8912,\n",
       " 'airless': 344,\n",
       " 'cinematic': 2423,\n",
       " 'shell': 13134,\n",
       " 'games': 6049,\n",
       " 'sure': 14468,\n",
       " 'filmmaker': 5536,\n",
       " 'disagree': 3999,\n",
       " 'honestly': 6996,\n",
       " 'point': 10937,\n",
       " 'jones': 8013,\n",
       " 'tackled': 14631,\n",
       " 'meaty': 9127,\n",
       " 'subject': 14315,\n",
       " 'drawn': 4355,\n",
       " 'engaging': 4790,\n",
       " 'characters': 2241,\n",
       " 'peppering': 10606,\n",
       " 'pages': 10360,\n",
       " 'memorable': 9182,\n",
       " 'zingers': 16710,\n",
       " 'bloody': 1473,\n",
       " 'sunday': 14428,\n",
       " 'grace': 6353,\n",
       " 'prevention': 11215,\n",
       " 'place': 10817,\n",
       " 'blame': 1400,\n",
       " 'making': 8889,\n",
       " 'clunky': 2589,\n",
       " 'approach': 647,\n",
       " 'detailing': 3850,\n",
       " 'chapter': 2229,\n",
       " 'life': 8526,\n",
       " 'celebrated': 2165,\n",
       " 'irish': 7837,\n",
       " 'playwright': 10869,\n",
       " 'poet': 10927,\n",
       " 'drinker': 4387,\n",
       " 'finally': 5544,\n",
       " 'coming': 2716,\n",
       " 'miramax': 9344,\n",
       " 'deep': 3607,\n",
       " 'shelves': 13137,\n",
       " 'couple': 3158,\n",
       " 'aborted': 24,\n",
       " 'attempts': 870,\n",
       " 'waking': 16163,\n",
       " 'reno': 12060,\n",
       " 'strong': 14226,\n",
       " 'letting': 8491,\n",
       " 'sleeping': 13440,\n",
       " 'thanks': 14864,\n",
       " 'largely': 8333,\n",
       " 'williams': 16430,\n",
       " 'interesting': 7713,\n",
       " 'developments': 3878,\n",
       " 'processed': 11275,\n",
       " 'rest': 12186,\n",
       " 'overexposed': 10267,\n",
       " 'waste': 16237,\n",
       " 'comes': 2703,\n",
       " 'relic': 12005,\n",
       " 'bygone': 1921,\n",
       " 'convolutions': 3077,\n",
       " 'silly': 13294,\n",
       " 'plausible': 10851,\n",
       " 'cliche': 2517,\n",
       " 'refreshing': 11908,\n",
       " 'lead': 8399,\n",
       " 'oscar': 10196,\n",
       " 'size': 13354,\n",
       " 'lives': 8634,\n",
       " 'mark': 8979,\n",
       " 'pellington': 10584,\n",
       " 'thriller': 14948,\n",
       " 'kooky': 8228,\n",
       " 'overeager': 10265,\n",
       " 'spooky': 13868,\n",
       " 'subtly': 14354,\n",
       " 'myth': 9682,\n",
       " 'claude': 2484,\n",
       " 'chabrol': 2194,\n",
       " 'camera': 1975,\n",
       " 'gently': 6147,\n",
       " 'swaying': 14550,\n",
       " 'forth': 5818,\n",
       " 'cradles': 3194,\n",
       " 'veiling': 15963,\n",
       " 'tension': 14813,\n",
       " 'beneath': 1265,\n",
       " 'tender': 14804,\n",
       " 'movements': 9584,\n",
       " 'transforms': 15194,\n",
       " 'shakespeare': 13071,\n",
       " 'deepest': 3611,\n",
       " 'tragedies': 15165,\n",
       " 'smart': 13511,\n",
       " 'screenplay': 12825,\n",
       " 'james': 7921,\n",
       " 'eric': 4917,\n",
       " 'horton': 7058,\n",
       " 'director': 3987,\n",
       " 'peter': 10693,\n",
       " 'fallon': 5307,\n",
       " 'teeth': 14769,\n",
       " 'hurt': 7152,\n",
       " 'arriving': 729,\n",
       " 'particularly': 10458,\n",
       " 'moment': 9453,\n",
       " 'history': 6928,\n",
       " 'flickering': 5666,\n",
       " 'reminders': 12040,\n",
       " 'ties': 14996,\n",
       " 'bind': 1351,\n",
       " 'generic': 6127,\n",
       " 'villains': 16062,\n",
       " 'lack': 8275,\n",
       " 'funny': 5996,\n",
       " 'accents': 63,\n",
       " 'scenes': 12732,\n",
       " 'poorly': 10986,\n",
       " 'delivered': 3690,\n",
       " 'deeply': 3612,\n",
       " 'thought': 14924,\n",
       " 'thinking': 14902,\n",
       " 'films': 5539,\n",
       " 'gratuitous': 6406,\n",
       " 'distractions': 4156,\n",
       " 'impressed': 7343,\n",
       " 'downright': 4305,\n",
       " 'transparent': 15207,\n",
       " 'endless': 4766,\n",
       " 'assault': 797,\n",
       " 'embarrassingly': 4678,\n",
       " 'fisted': 5586,\n",
       " 'jokes': 8002,\n",
       " 'reek': 11878,\n",
       " 'rewrite': 12289,\n",
       " 'designed': 3815,\n",
       " 'garner': 6072,\n",
       " 'cooler': 3084,\n",
       " 'rating': 11703,\n",
       " 'provocative': 11401,\n",
       " 'impossible': 7338,\n",
       " 'gets': 6167,\n",
       " 'skin': 13389,\n",
       " 'know': 8215,\n",
       " 'evil': 5028,\n",
       " 'monstrous': 9481,\n",
       " 'lunatic': 8785,\n",
       " 'drive': 4392,\n",
       " 'things': 14899,\n",
       " 'stoner': 14134,\n",
       " 'midnight': 9270,\n",
       " 'deconstruction': 3591,\n",
       " 'fantasia': 5338,\n",
       " 'sanguine': 12640,\n",
       " 'skittish': 13401,\n",
       " 'york': 16671,\n",
       " 'middle': 9264,\n",
       " 'agers': 305,\n",
       " 'stumble': 14267,\n",
       " 'relationship': 11981,\n",
       " 'struggle': 14236,\n",
       " 'furiously': 5999,\n",
       " 'fears': 5413,\n",
       " 'foibles': 5733,\n",
       " 'ambition': 447,\n",
       " 'subjects': 14319,\n",
       " 'willingness': 16435,\n",
       " 'scherfig': 12743,\n",
       " 'wondering': 16527,\n",
       " 'clever': 2512,\n",
       " 'credits': 3252,\n",
       " 'roll': 12423,\n",
       " 'absorbing': 40,\n",
       " 'documentary': 4209,\n",
       " 'reeks': 11881,\n",
       " 'hack': 6576,\n",
       " 'vignettes': 16055,\n",
       " 'clips': 2540,\n",
       " 'looking': 8691,\n",
       " 'common': 2737,\n",
       " 'line': 8581,\n",
       " 'contrived': 3041,\n",
       " 'pastiche': 10497,\n",
       " 'caper': 2019,\n",
       " 'major': 8878,\n",
       " 'problem': 11266,\n",
       " 'bulk': 1842,\n",
       " 'centers': 2183,\n",
       " 'wrong': 16623,\n",
       " 'swimfan': 14568,\n",
       " 'attraction': 881,\n",
       " 'eventually': 5015,\n",
       " 'goes': 6285,\n",
       " 'overboard': 10253,\n",
       " 'loony': 8695,\n",
       " 'melodramatic': 9169,\n",
       " 'denouement': 3737,\n",
       " 'school': 12761,\n",
       " 'swimming': 14570,\n",
       " 'pool': 10983,\n",
       " 'substitutes': 14343,\n",
       " 'bathtub': 1142,\n",
       " 'heartfelt': 6777,\n",
       " 'involving': 7827,\n",
       " 'unsettling': 15793,\n",
       " 'experience': 5143,\n",
       " 'predecessors': 11130,\n",
       " 'proud': 11385,\n",
       " 'pretty': 11209,\n",
       " 'execution': 5092,\n",
       " 'richer': 12313,\n",
       " 'ones': 10100,\n",
       " 'hollywood': 6971,\n",
       " 'screenwriters': 12829,\n",
       " 'usually': 15890,\n",
       " 'come': 2694,\n",
       " 'phillip': 10714,\n",
       " 'noyce': 9957,\n",
       " 'cinematographer': 2425,\n",
       " 'christopher': 2399,\n",
       " 'doyle': 4314,\n",
       " 'understand': 15565,\n",
       " 'delicate': 3674,\n",
       " 'forcefulness': 5770,\n",
       " 'greene': 6431,\n",
       " 'prose': 11372,\n",
       " 'version': 16005,\n",
       " 'american': 457,\n",
       " 'pianist': 10746,\n",
       " 'lacks': 8280,\n",
       " 'quick': 11568,\n",
       " 'emotional': 4705,\n",
       " 'connections': 2927,\n",
       " 'steven': 14075,\n",
       " 'spielberg': 13801,\n",
       " 'schindler': 12746,\n",
       " 'list': 8611,\n",
       " 'inventive': 7800,\n",
       " 'intoxicatingly': 7767,\n",
       " 'sexy': 13053,\n",
       " 'violent': 16074,\n",
       " 'maddening': 8831,\n",
       " 'tells': 14784,\n",
       " 'fascinating': 5364,\n",
       " 'compelling': 2769,\n",
       " 'written': 16622,\n",
       " 'flatly': 5629,\n",
       " 'kendall': 8129,\n",
       " 'directed': 3980,\n",
       " 'barely': 1092,\n",
       " 'mary': 9020,\n",
       " 'writer': 16616,\n",
       " 'decter': 3600,\n",
       " 'highly': 6890,\n",
       " 'recommended': 11815,\n",
       " 'viewing': 16049,\n",
       " 'courage': 3162,\n",
       " 'ideas': 7203,\n",
       " 'technical': 14745,\n",
       " 'proficiency': 11302,\n",
       " 'great': 6422,\n",
       " 'acting': 131,\n",
       " 'imax': 7265,\n",
       " 'short': 13194,\n",
       " 'wonderful': 16525,\n",
       " 'shows': 13224,\n",
       " 'slice': 13448,\n",
       " 'instantly': 7647,\n",
       " 'recognizable': 11806,\n",
       " 'amid': 465,\n",
       " 'shock': 13168,\n",
       " 'curiosity': 3384,\n",
       " 'factors': 5272,\n",
       " 'corny': 3116,\n",
       " 'examination': 5049,\n",
       " 'actress': 147,\n",
       " 'trying': 15350,\n",
       " 'lazy': 8398,\n",
       " 'solving': 13654,\n",
       " 'distract': 4152,\n",
       " 'solution': 13651,\n",
       " 'comprehensible': 2812,\n",
       " 'dummies': 4459,\n",
       " 'guide': 6533,\n",
       " 'techies': 14744,\n",
       " 'enjoy': 4809,\n",
       " 'entertains': 4849,\n",
       " 'music': 9649,\n",
       " 'comic': 2711,\n",
       " 'antics': 579,\n",
       " 'pleasure': 10882,\n",
       " 'disney': 4089,\n",
       " 'scrape': 12808,\n",
       " 'cracker': 3187,\n",
       " 'barrel': 1105,\n",
       " 'burr': 1886,\n",
       " 'steers': 14049,\n",
       " 'emphasizes': 4716,\n",
       " 'quirky': 11585,\n",
       " 'mixed': 9408,\n",
       " 'results': 12201,\n",
       " 'scarcely': 12710,\n",
       " 'mention': 9195,\n",
       " 'reporting': 12092,\n",
       " 'number': 9969,\n",
       " 'tumbleweeds': 15362,\n",
       " 'blowing': 1477,\n",
       " 'theatres': 14870,\n",
       " 'graced': 6354,\n",
       " 'company': 2754,\n",
       " 'invigorating': 7813,\n",
       " 'surreal': 14491,\n",
       " 'resonant': 12160,\n",
       " 'rainbow': 11632,\n",
       " 'emotion': 4704,\n",
       " 'analyze': 495,\n",
       " 'crass': 3215,\n",
       " 'sequels': 12983,\n",
       " 'fails': 5285,\n",
       " 'second': 12879,\n",
       " 'guess': 6525,\n",
       " 'affection': 263,\n",
       " 'original': 10182,\n",
       " 'report': 12088,\n",
       " 'card': 2041,\n",
       " 'live': 8627,\n",
       " 'exalted': 5046,\n",
       " 'tagline': 14641,\n",
       " 'definite': 3635,\n",
       " 'room': 12453,\n",
       " 'improvement': 7361,\n",
       " 'monsterous': 9479,\n",
       " 'tsai': 15352,\n",
       " 'ploughing': 10902,\n",
       " 'furrow': 6001,\n",
       " 'green': 6430,\n",
       " 'equivalent': 4911,\n",
       " 'saddam': 12570,\n",
       " 'hussein': 7159,\n",
       " 'ready': 11742,\n",
       " 'permission': 10644,\n",
       " 'preemptive': 11138,\n",
       " 'strike': 14208,\n",
       " 'surprisingly': 14490,\n",
       " 'solid': 13641,\n",
       " 'achievement': 108,\n",
       " 'malcolm': 8896,\n",
       " 'john': 7990,\n",
       " 'ridley': 12333,\n",
       " 'massoud': 9037,\n",
       " 'record': 11824,\n",
       " 'tenacious': 14798,\n",
       " 'humane': 7110,\n",
       " 'fighter': 5511,\n",
       " 'prisoner': 11251,\n",
       " 'victim': 16028,\n",
       " 'changing': 2219,\n",
       " 'lanes': 8314,\n",
       " 'tries': 15280,\n",
       " 'shyamalan': 13249,\n",
       " 'stop': 14140,\n",
       " 'macabre': 8815,\n",
       " 'stylized': 14305,\n",
       " 'swedish': 14555,\n",
       " 'fillm': 5528,\n",
       " 'city': 2442,\n",
       " 'religious': 12012,\n",
       " 'civic': 2443,\n",
       " 'virtues': 16082,\n",
       " 'hold': 6958,\n",
       " 'society': 13605,\n",
       " 'tatters': 14710,\n",
       " 'recent': 11791,\n",
       " 'memory': 9186,\n",
       " 'thoughtful': 14925,\n",
       " 'ethics': 4978,\n",
       " 'cost': 3129,\n",
       " 'moral': 9506,\n",
       " 'compromise': 2817,\n",
       " 'consistently': 2956,\n",
       " 'unimaginative': 15676,\n",
       " 'probably': 11261,\n",
       " 'saved': 12685,\n",
       " 'wisecracking': 16480,\n",
       " 'mystery': 9675,\n",
       " 'science': 12778,\n",
       " 'guys': 6569,\n",
       " 'tian': 14979,\n",
       " 'zhuangzhuang': 16705,\n",
       " 'triumphantly': 15302,\n",
       " 'returns': 12238,\n",
       " 'filmmaking': 5538,\n",
       " 'visually': 16104,\n",
       " 'masterful': 9039,\n",
       " 'power': 11078,\n",
       " 'mawkish': 9077,\n",
       " 'parody': 10445,\n",
       " 'weird': 16321,\n",
       " 'masterpiece': 9044,\n",
       " 'sketch': 13369,\n",
       " 'view': 16044,\n",
       " 'believe': 1241,\n",
       " 'puts': 11518,\n",
       " 'battle': 1148,\n",
       " 'wills': 16437,\n",
       " 'care': 2047,\n",
       " 'appreciate': 641,\n",
       " 'sided': 13259,\n",
       " 'theme': 14879,\n",
       " 'lawrence': 8385,\n",
       " 'tirade': 15029,\n",
       " 'knock': 8205,\n",
       " 'postcard': 11050,\n",
       " 'glorified': 6253,\n",
       " 'martin': 9006,\n",
       " 'lovefest': 8738,\n",
       " 'sneaky': 13565,\n",
       " 'dupe': 4468,\n",
       " 'viewer': 16046,\n",
       " 'taking': 14652,\n",
       " 'important': 7335,\n",
       " 'simply': 13311,\n",
       " 'ugly': 15437,\n",
       " 'look': 8688,\n",
       " 'product': 11287,\n",
       " 'threatens': 14941,\n",
       " 'bogged': 1531,\n",
       " 'dramaturgy': 4345,\n",
       " 'stirring': 14111,\n",
       " 'sequence': 12984,\n",
       " 'surge': 14481,\n",
       " 'swirling': 14579,\n",
       " 'rapids': 11684,\n",
       " 'leap': 8413,\n",
       " 'pinnacle': 10786,\n",
       " 'rouses': 12488,\n",
       " 'swinging': 14574,\n",
       " 'hobby': 6947,\n",
       " 'attracts': 884,\n",
       " 'entirely': 4862,\n",
       " 'unprepared': 15753,\n",
       " 'devos': 3892,\n",
       " 'delivers': 3692,\n",
       " 'perfect': 10621,\n",
       " 'captures': 2038,\n",
       " 'innocence': 7584,\n",
       " 'budding': 1823,\n",
       " 'demons': 3722,\n",
       " 'wallflower': 16175,\n",
       " 'years': 16657,\n",
       " 'russian': 12540,\n",
       " 'culture': 3375,\n",
       " 'compressed': 2815,\n",
       " 'evanescent': 5000,\n",
       " 'seamless': 12858,\n",
       " 'sumptuous': 14423,\n",
       " 'stream': 14186,\n",
       " 'consciousness': 2941,\n",
       " 'filmmakers': 5537,\n",
       " 'want': 16200,\n",
       " 'cheap': 2276,\n",
       " 'succeed': 14359,\n",
       " 'polanski': 10953,\n",
       " 'element': 4632,\n",
       " 'abandoned': 3,\n",
       " 'consoled': 2959,\n",
       " 'revealed': 12242,\n",
       " 'spiritual': 13826,\n",
       " 'survival': 14507,\n",
       " 'spider': 13797,\n",
       " 'summer': 14419,\n",
       " 'blockbuster': 1459,\n",
       " 'endure': 4772,\n",
       " 'hopefully': 7026,\n",
       " 'sets': 13023,\n",
       " 'tone': 15073,\n",
       " 'stuff': 14259,\n",
       " 'turpin': 15396,\n",
       " 'vulgar': 16138,\n",
       " 'forgettably': 5791,\n",
       " 'images': 7254,\n",
       " 'ravaged': 11715,\n",
       " 'land': 8305,\n",
       " 'prove': 11386,\n",
       " 'potent': 11061,\n",
       " 'riveting': 12380,\n",
       " 'unlikely': 15717,\n",
       " 'sarah': 12650,\n",
       " 'harrison': 6699,\n",
       " 'winds': 16454,\n",
       " 'revelatory': 12248,\n",
       " 'narcissistic': 9718,\n",
       " 'achieving': 111,\n",
       " 'honest': 6995,\n",
       " 'insight': 7614,\n",
       " 'relationships': 11982,\n",
       " 'concept': 2839,\n",
       " 'candy': 2001,\n",
       " 'coat': 2602,\n",
       " 'storylines': 14154,\n",
       " 'precious': 11116,\n",
       " 'circumstances': 2436,\n",
       " 'beautiful': 1181,\n",
       " 'stars': 14001,\n",
       " 'martha': 9004,\n",
       " 'unsurprising': 15813,\n",
       " 'delectable': 3660,\n",
       " 'diversion': 4177,\n",
       " 'affecting': 261,\n",
       " 'portrait': 11018,\n",
       " 'screwed': 12832,\n",
       " 'dared': 3475,\n",
       " 'powerful': 11080,\n",
       " 'people': 10601,\n",
       " 'seen': 12909,\n",
       " 'eyes': 5247,\n",
       " 'idealistic': 7199,\n",
       " 'chooses': 2371,\n",
       " 'champion': 2209,\n",
       " 'losing': 8716,\n",
       " 'cause': 2148,\n",
       " 'keenly': 8125,\n",
       " 'observed': 10015,\n",
       " 'refreshingly': 11909,\n",
       " 'natural': 9747,\n",
       " 'details': 3851,\n",
       " 'promenade': 11335,\n",
       " 'clad': 2449,\n",
       " 'bodies': 1525,\n",
       " 'myrtle': 9672,\n",
       " 'beach': 1154,\n",
       " 'adrenaline': 219,\n",
       " 'jolt': 8007,\n",
       " 'sudden': 14378,\n",
       " 'lunch': 8786,\n",
       " 'rush': 12535,\n",
       " 'diner': 3968,\n",
       " 'brilliant': 1743,\n",
       " 'expense': 5141,\n",
       " 'paid': 10361,\n",
       " 'triumph': 15300,\n",
       " 'hews': 6864,\n",
       " 'carries': 2083,\n",
       " 'effortlessly': 4591,\n",
       " 'darkness': 3485,\n",
       " 'light': 8536,\n",
       " 'involved': 7824,\n",
       " 'coasting': 2601,\n",
       " 'hooked': 7013,\n",
       " 'delicious': 3676,\n",
       " 'pulpiness': 11452,\n",
       " 'lurid': 8791,\n",
       " 'fiction': 5485,\n",
       " 'kind': 8168,\n",
       " 'production': 11288,\n",
       " 'funnier': 5993,\n",
       " 'released': 11992,\n",
       " 'outtakes': 10242,\n",
       " 'theatrically': 14872,\n",
       " 'used': 15879,\n",
       " 'bonus': 1580,\n",
       " 'tolstoy': 15063,\n",
       " 'groupies': 6497,\n",
       " 'daughter': 3499,\n",
       " 'danang': 3454,\n",
       " 'reveals': 12244,\n",
       " 'efforts': 4592,\n",
       " 'closure': 2564,\n",
       " 'open': 10116,\n",
       " 'wounds': 16590,\n",
       " 'weirdly': 16324,\n",
       " 'unpredictable': 15752,\n",
       " 'pieces': 10761,\n",
       " 'intriguing': 7776,\n",
       " 'intoxicating': 7766,\n",
       " 'fairly': 5292,\n",
       " 'having': 6729,\n",
       " 'fresh': 5899,\n",
       " 'growing': 6500,\n",
       " 'catholic': 2139,\n",
       " 'really': 11758,\n",
       " 'comprehension': 2813,\n",
       " 'sleek': 13434,\n",
       " 'arty': 762,\n",
       " 'poor': 10985,\n",
       " 'editing': 4567,\n",
       " 'bluescreen': 1489,\n",
       " 'ultra': 15441,\n",
       " 'cheesy': 2306,\n",
       " 'highlight': 6887,\n",
       " 'radical': 11616,\n",
       " 'face': 5259,\n",
       " 'amazing': 440,\n",
       " 'slapstick': 13420,\n",
       " 'instrument': 7661,\n",
       " 'creating': 3238,\n",
       " 'scrapbook': 12807,\n",
       " 'living': 8635,\n",
       " 'shots': 13203,\n",
       " 'frame': 5846,\n",
       " 'completely': 2790,\n",
       " 'misses': 9389,\n",
       " 'emotions': 4707,\n",
       " 'initial': 7569,\n",
       " 'strangeness': 14172,\n",
       " 'inexorably': 7502,\n",
       " 'rote': 12473,\n",
       " 'sentimentality': 12970,\n",
       " 'mystical': 9677,\n",
       " 'tenderness': 14806,\n",
       " 'expedience': 5138,\n",
       " 'lets': 8487,\n",
       " 'brush': 1804,\n",
       " 'humanity': 7115,\n",
       " 'psycho': 11421,\n",
       " 'hartley': 6705,\n",
       " 'created': 3236,\n",
       " 'monster': 9478,\n",
       " 'handle': 6634,\n",
       " 'cowering': 3181,\n",
       " 'begging': 1211,\n",
       " 'feet': 5436,\n",
       " 'scruffy': 12846,\n",
       " 'giannini': 6178,\n",
       " 'madonna': 8836,\n",
       " 'abel': 11,\n",
       " 'ferrara': 5457,\n",
       " 'beaten': 1172,\n",
       " 'pulp': 11451,\n",
       " 'dangerous': 3461,\n",
       " 'game': 6047,\n",
       " 'clumsy': 2584,\n",
       " 'moments': 9455,\n",
       " 'splash': 13836,\n",
       " 'legged': 8449,\n",
       " 'freaks': 5874,\n",
       " 'partly': 10462,\n",
       " 'homage': 6979,\n",
       " 'tarantula': 14688,\n",
       " 'budget': 1825,\n",
       " 'thrillers': 14949,\n",
       " 'sophomoric': 13682,\n",
       " 'romp': 12449,\n",
       " 'hellish': 6822,\n",
       " 'conditions': 2869,\n",
       " 'errol': 4930,\n",
       " 'morris': 9532,\n",
       " 'focusing': 5731,\n",
       " 'eccentricity': 4539,\n",
       " 'failing': 5283,\n",
       " 'bigger': 1334,\n",
       " 'oddballs': 10044,\n",
       " 'near': 9768,\n",
       " 'future': 6015,\n",
       " 'america': 456,\n",
       " 'scientific': 12779,\n",
       " 'discerned': 4021,\n",
       " 'producers': 11284,\n",
       " 'heed': 6804,\n",
       " 'mediocre': 9139,\n",
       " 'drag': 4323,\n",
       " 'speeds': 13782,\n",
       " 'explosions': 5177,\n",
       " 'fall': 5302,\n",
       " 'cool': 3083,\n",
       " 'aware': 962,\n",
       " 'coolness': 3086,\n",
       " 'artist': 748,\n",
       " ...}"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v7VIjRpN2uG",
    "outputId": "532a00d3-713a-4022-f5e5-c8dd8663f62c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaliyah',\n",
       " 'abagnale',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandons',\n",
       " 'abbas',\n",
       " 'abbass',\n",
       " 'abbott',\n",
       " 'abbreviated',\n",
       " 'abderrahmane',\n",
       " 'abdul',\n",
       " 'abel',\n",
       " 'aberration',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abiding',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abomination',\n",
       " 'aborbing',\n",
       " 'aboriginal',\n",
       " 'aborted',\n",
       " 'aboul',\n",
       " 'abound',\n",
       " 'abrahams',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abridged',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuating',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accommodate',\n",
       " 'accomodates',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'according',\n",
       " 'accordion',\n",
       " 'accorsi',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accounting',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'acerbic',\n",
       " 'ache',\n",
       " 'achero',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achival',\n",
       " 'achronological',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidity',\n",
       " 'ackerman',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acolytes',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activism',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actorish',\n",
       " 'actorliness',\n",
       " 'actorly',\n",
       " 'actors',\n",
       " 'actory',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualization',\n",
       " 'actually',\n",
       " 'actuary',\n",
       " 'acumen',\n",
       " 'acute',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adapts',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addessi',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherents',\n",
       " 'adhering',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adopts',\n",
       " 'adorability',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adoring',\n",
       " 'adorned',\n",
       " 'adorns',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalized',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'adult',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventues',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversity',\n",
       " 'advert',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advises',\n",
       " 'advocacy',\n",
       " 'aerial',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectingly',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmational',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'afflicting',\n",
       " 'afflicts',\n",
       " 'affluence',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'afforded',\n",
       " 'affords',\n",
       " 'affronted',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterschool',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'agape',\n",
       " 'aged',\n",
       " 'ageism',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'agers',\n",
       " 'ages',\n",
       " 'agey',\n",
       " 'aggrandizing',\n",
       " 'aggravating',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressiveness',\n",
       " 'aggrieved',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'agitator',\n",
       " 'agitprop',\n",
       " 'agnostic',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agreeable',\n",
       " 'agreeably',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'aground',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahhhh',\n",
       " 'ahola',\n",
       " 'aidan',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'ailments',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aimlessness',\n",
       " 'aims',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'airless',\n",
       " 'airport',\n",
       " 'airs',\n",
       " 'airtime',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'akasha',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'alabama',\n",
       " 'alacrity',\n",
       " 'aladdin',\n",
       " 'alagna',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarmingly',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcatraz',\n",
       " 'alchemical',\n",
       " 'alchemy',\n",
       " 'alcoholic',\n",
       " 'aldrich',\n",
       " 'aleck',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'alientation',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegorical',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'alleys',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allison',\n",
       " 'allodi',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluring',\n",
       " 'allusions',\n",
       " 'ally',\n",
       " 'allying',\n",
       " 'almodovar',\n",
       " 'aloft',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alpha',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'alzheimer',\n",
       " 'amalgam',\n",
       " 'amalgamating',\n",
       " 'amari',\n",
       " 'amaro',\n",
       " 'amassed',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amateurishness',\n",
       " 'amaze',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amber',\n",
       " 'ambience',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'amble',\n",
       " 'ambling',\n",
       " 'ambrose',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'amiability',\n",
       " 'amiable',\n",
       " 'amiably',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amini',\n",
       " 'amir',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amorous',\n",
       " 'amos',\n",
       " 'amoses',\n",
       " 'amounts',\n",
       " 'amours',\n",
       " 'amped',\n",
       " 'ample',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusedly',\n",
       " 'amusement',\n",
       " 'amusements',\n",
       " 'amuses',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'anachronistic',\n",
       " 'anakin',\n",
       " 'analgesic',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'analyze',\n",
       " 'anarchic',\n",
       " 'anarchist',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'anatomical',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'anchoring',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'anciently',\n",
       " 'ancillary',\n",
       " 'anderson',\n",
       " 'andersson',\n",
       " 'andie',\n",
       " 'andrei',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'andys',\n",
       " 'anecdote',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelina',\n",
       " 'angelique',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angling',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anguish',\n",
       " 'anguished',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animations',\n",
       " 'animaton',\n",
       " 'animator',\n",
       " 'animatronic',\n",
       " 'anime',\n",
       " 'aniston',\n",
       " 'ankle',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'anne',\n",
       " 'annex',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annoyance',\n",
       " 'annoyances',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'annual',\n",
       " 'anomaly',\n",
       " 'anomie',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'anspaugh',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'antagonism',\n",
       " 'antagonists',\n",
       " 'ante',\n",
       " 'anteing',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthropologically',\n",
       " 'anthropology',\n",
       " 'anthropomorphic',\n",
       " 'anti',\n",
       " 'antic',\n",
       " 'anticipated',\n",
       " 'anticipation',\n",
       " 'antics',\n",
       " 'antidote',\n",
       " 'antidotes',\n",
       " 'antique',\n",
       " 'antiseptic',\n",
       " 'antithesis',\n",
       " 'antitrust',\n",
       " 'antlers',\n",
       " 'anton',\n",
       " 'antonia',\n",
       " 'antonio',\n",
       " 'ants',\n",
       " 'antsy',\n",
       " 'antwone',\n",
       " 'anxieties',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyplace',\n",
       " 'anytime',\n",
       " 'apallingly',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'apes',\n",
       " 'apex',\n",
       " 'aplenty',\n",
       " 'aplomb',\n",
       " 'apocalypse',\n",
       " 'apolitical',\n",
       " 'apollo',\n",
       " 'apology',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appealingly',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appetite',\n",
       " 'appetites',\n",
       " 'appetizer',\n",
       " 'appetizing',\n",
       " 'applaud',\n",
       " 'applauded',\n",
       " 'apple',\n",
       " 'applegate',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointed',\n",
       " 'appraisal',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehension',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'approximation',\n",
       " 'april',\n",
       " 'apted',\n",
       " 'aptitude',\n",
       " 'aptly',\n",
       " 'aquatic',\n",
       " 'aragorn',\n",
       " 'aranda',\n",
       " 'ararat',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arcana',\n",
       " 'arcane',\n",
       " 'arch',\n",
       " 'archetypal',\n",
       " 'archibald',\n",
       " 'architect',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'archival',\n",
       " 'archive',\n",
       " 'archives',\n",
       " 'archly',\n",
       " 'arctic',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'ardor',\n",
       " 'arduous',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arena',\n",
       " 'argentine',\n",
       " 'argentinean',\n",
       " 'argentinian',\n",
       " 'argento',\n",
       " 'argot',\n",
       " 'arguable',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arise',\n",
       " 'arising',\n",
       " 'aristocracy',\n",
       " 'aristocrat',\n",
       " 'aristocratic',\n",
       " 'aristocrats',\n",
       " 'arithmetic',\n",
       " 'arkansas',\n",
       " 'arkin',\n",
       " 'arliss',\n",
       " 'armageddon',\n",
       " 'armchair',\n",
       " 'armed',\n",
       " 'armenia',\n",
       " 'armenian',\n",
       " 'armenians',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'arouse',\n",
       " 'aroused',\n",
       " 'arousing',\n",
       " 'arquette',\n",
       " 'arrangements',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arresting',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'artefact',\n",
       " 'arteta',\n",
       " 'artful',\n",
       " 'artfully',\n",
       " 'arthouse',\n",
       " 'arthritic',\n",
       " 'arthur',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'articulates',\n",
       " 'artifact',\n",
       " 'artifacts',\n",
       " 'artifice',\n",
       " 'artificial',\n",
       " 'artificiality',\n",
       " 'artist',\n",
       " 'artiste',\n",
       " 'artistes',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'artists',\n",
       " 'artless',\n",
       " 'artnering',\n",
       " 'arts',\n",
       " 'artsploitation',\n",
       " 'artsy',\n",
       " 'artwork',\n",
       " 'artworks',\n",
       " 'arty',\n",
       " 'arwen',\n",
       " 'asay',\n",
       " 'asbury',\n",
       " 'ascends',\n",
       " 'ascension',\n",
       " 'ascertain',\n",
       " 'ashamed',\n",
       " 'ashes',\n",
       " 'ashley',\n",
       " 'ashtray',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiaphiles',\n",
       " 'aside',\n",
       " 'asinine',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspiration',\n",
       " 'aspirations',\n",
       " 'aspire',\n",
       " 'aspired',\n",
       " 'aspires',\n",
       " 'aspiring',\n",
       " 'asquith',\n",
       " 'assailants',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assassins',\n",
       " 'assault',\n",
       " 'assaultive',\n",
       " 'assaults',\n",
       " 'assayas',\n",
       " 'assed',\n",
       " 'assembled',\n",
       " 'assembles',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'assertive',\n",
       " 'assess',\n",
       " 'assesses',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assimilated',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'assuredness',\n",
       " 'assures',\n",
       " 'astonish',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astoria',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astounds',\n",
       " 'astray',\n",
       " 'astringent',\n",
       " 'astronaut',\n",
       " 'astronauts',\n",
       " 'astronomically',\n",
       " 'astute',\n",
       " 'asylum',\n",
       " 'atavistic',\n",
       " 'atheistic',\n",
       " 'athlete',\n",
       " 'athletes',\n",
       " 'athletic',\n",
       " 'athleticism',\n",
       " 'athon',\n",
       " 'atlantic',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atmospherics',\n",
       " 'atom',\n",
       " 'atonal',\n",
       " 'atop',\n",
       " 'atrocious',\n",
       " 'atrociously',\n",
       " 'atrocities',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attackers',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attal',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attendant',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attentive',\n",
       " 'attics',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attract',\n",
       " 'attracting',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attributable',\n",
       " 'attuned',\n",
       " 'atypically',\n",
       " 'audacious',\n",
       " 'audacity',\n",
       " 'audiard',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'auditorium',\n",
       " 'audrey',\n",
       " 'augmentation',\n",
       " 'augmented',\n",
       " 'august',\n",
       " 'augustine',\n",
       " 'augustinian',\n",
       " 'aura',\n",
       " 'aurelie',\n",
       " 'auschwitz',\n",
       " 'auspicious',\n",
       " 'aussie',\n",
       " 'austen',\n",
       " 'austere',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austrian',\n",
       " 'auteil',\n",
       " 'auteuil',\n",
       " 'auteur',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticate',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'authors',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'autobiographical',\n",
       " 'autocritique',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autopilot',\n",
       " 'autopsy',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avalanches',\n",
       " 'avant',\n",
       " 'avarice',\n",
       " 'avary',\n",
       " 'avengers',\n",
       " 'avenges',\n",
       " 'avenues',\n",
       " 'average',\n",
       " 'averse',\n",
       " 'aversion',\n",
       " 'avert',\n",
       " 'averting',\n",
       " 'avid',\n",
       " 'avis',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'avon',\n",
       " 'avuncular',\n",
       " 'avventura',\n",
       " 'awake',\n",
       " 'awakening',\n",
       " 'awakens',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awash',\n",
       " 'away',\n",
       " 'awed',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awfulness',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awkwardness',\n",
       " 'awry',\n",
       " 'axel',\n",
       " 'axis',\n",
       " 'ayala',\n",
       " 'ayatollah',\n",
       " 'ayres',\n",
       " 'ayurveda',\n",
       " 'baaaaaaaaad',\n",
       " 'baader',\n",
       " 'babak',\n",
       " 'babbitt',\n",
       " 'babes',\n",
       " 'babies',\n",
       " 'baboon',\n",
       " 'baby',\n",
       " 'babysitter',\n",
       " 'baca',\n",
       " 'backbone',\n",
       " 'backdrop',\n",
       " 'backdrops',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backgrounds',\n",
       " 'backhanded',\n",
       " 'backlash',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Text_Mining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
